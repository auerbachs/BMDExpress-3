{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Data Integration\n",
    "\n",
    "Basic notebook for data integration tasks:\n",
    "1. Create datasets from DuckDB\n",
    "2. Parse TypeScript interface from .ts file  \n",
    "3. Parse JSON data into Python objects\n",
    "4. Merge datasets\n",
    "5. Create rank/dose pairs from query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from bmd_duckdb_sink import BMDExpressDuckDBSink\n",
    "\n",
    "print(\"Imports ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Datasets from DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and create datasets\n",
    "sink = BMDExpressDuckDBSink(\"dehp_analysis.duckdb\")\n",
    "sink.connect()\n",
    "\n",
    "# Dataset 1: Basic probe data\n",
    "probe_dataset = sink.execute_query(\"\"\"\n",
    "    SELECT \n",
    "        p.id as probe_id,\n",
    "        p.probeSet,\n",
    "        rg.geneSymbol,\n",
    "        rg.geneName\n",
    "    FROM probes p\n",
    "    LEFT JOIN referenceGeneAnnotations rga ON p.id = rga.probeId\n",
    "    LEFT JOIN referenceGenes rg ON rga.referenceGeneId = rg.id\n",
    "    WHERE rg.geneSymbol IS NOT NULL\n",
    "    LIMIT 50\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Probe dataset: {len(probe_dataset)} records\")\n",
    "probe_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 2: Dose information \n",
    "dose_dataset = sink.execute_query(\"\"\"\n",
    "    SELECT \n",
    "        dose,\n",
    "        COUNT(*) as dose_count,\n",
    "        AVG(n) as avg_sample_size\n",
    "    FROM doseGroups \n",
    "    GROUP BY dose \n",
    "    ORDER BY dose\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Dose dataset: {len(dose_dataset)} records\")\n",
    "dose_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse TypeScript Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple TypeScript interface parser\n",
    "def parse_ts_interface(ts_content):\n",
    "    \"\"\"Parse a simple TypeScript interface - you can expand this\"\"\"\n",
    "    \n",
    "    # Find interface name\n",
    "    interface_match = re.search(r'interface\\s+(\\w+)', ts_content)\n",
    "    interface_name = interface_match.group(1) if interface_match else \"Unknown\"\n",
    "    \n",
    "    # Find properties (simple regex - you can make this more sophisticated)\n",
    "    properties = []\n",
    "    prop_pattern = r'(\\w+)(\\??):\\s*([^;\\n]+)'\n",
    "    \n",
    "    for match in re.finditer(prop_pattern, ts_content):\n",
    "        prop_name = match.group(1)\n",
    "        is_optional = match.group(2) == '?'\n",
    "        prop_type = match.group(3).strip()\n",
    "        \n",
    "        properties.append({\n",
    "            'name': prop_name,\n",
    "            'type': prop_type,\n",
    "            'optional': is_optional\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'interface_name': interface_name,\n",
    "        'properties': properties\n",
    "    }\n",
    "\n",
    "# Example TypeScript content (replace with your actual .ts file content)\n",
    "sample_ts = \"\"\"\n",
    "interface ProbeResult {\n",
    "    id: number;\n",
    "    probeSet: string;\n",
    "    geneSymbol?: string;\n",
    "    bmdValue: number;\n",
    "    rank: number;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Parse the interface\n",
    "ts_schema = parse_ts_interface(sample_ts)\n",
    "print(f\"Parsed interface: {ts_schema['interface_name']}\")\n",
    "print(\"Properties:\")\n",
    "for prop in ts_schema['properties']:\n",
    "    optional = \"?\" if prop['optional'] else \"\"\n",
    "    print(f\"  {prop['name']}{optional}: {prop['type']}\")\n",
    "\n",
    "# TODO: Replace sample_ts with actual file content\n",
    "# with open('your_file.ts', 'r') as f:\n",
    "#     ts_content = f.read()\n",
    "#     ts_schema = parse_ts_interface(ts_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse JSON to Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON data (replace with your actual JSON)\n",
    "sample_json = {\n",
    "    \"results\": [\n",
    "        {\"id\": 1, \"probeSet\": \"Probe_001\", \"geneSymbol\": \"GENE1\", \"bmdValue\": 5.2, \"rank\": 1},\n",
    "        {\"id\": 2, \"probeSet\": \"Probe_002\", \"geneSymbol\": \"GENE2\", \"bmdValue\": 8.7, \"rank\": 2},\n",
    "        {\"id\": 3, \"probeSet\": \"Probe_003\", \"geneSymbol\": \"GENE3\", \"bmdValue\": 12.1, \"rank\": 3}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert JSON to Python objects/DataFrame\n",
    "def json_to_dataframe(json_data, results_key=\"results\"):\n",
    "    \"\"\"Convert JSON data to DataFrame\"\"\"\n",
    "    \n",
    "    if results_key in json_data:\n",
    "        data = json_data[results_key]\n",
    "    elif isinstance(json_data, list):\n",
    "        data = json_data\n",
    "    else:\n",
    "        data = [json_data]\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create DataFrame from JSON\n",
    "json_dataset = json_to_dataframe(sample_json)\n",
    "\n",
    "print(f\"JSON dataset: {len(json_dataset)} records\")\n",
    "json_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load from actual JSON file\n",
    "# with open('your_data.json', 'r') as f:\n",
    "#     json_data = json.load(f)\n",
    "#     json_dataset = json_to_dataframe(json_data)\n",
    "\n",
    "print(\"JSON parsing ready - replace sample data with your files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets\n",
    "# Example: merge probe data with JSON data on probe info\n",
    "\n",
    "# First, let's see what columns we have\n",
    "print(\"Probe dataset columns:\", probe_dataset.columns.tolist())\n",
    "print(\"JSON dataset columns:\", json_dataset.columns.tolist())\n",
    "\n",
    "# Simple merge example - you'll customize this\n",
    "# Let's create a common key for merging\n",
    "merged_dataset = pd.merge(\n",
    "    probe_dataset, \n",
    "    json_dataset, \n",
    "    left_on='geneSymbol',  # Adjust column names as needed\n",
    "    right_on='geneSymbol',\n",
    "    how='inner',  # or 'left', 'right', 'outer'\n",
    "    suffixes=('_db', '_json')\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset: {len(merged_dataset)} records\")\n",
    "merged_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative merge: Add dose information\n",
    "# Create a comprehensive dataset by adding dose info\n",
    "\n",
    "# Add max dose as a reference point\n",
    "max_dose = dose_dataset['dose'].max()\n",
    "merged_dataset['max_dose'] = max_dose\n",
    "\n",
    "print(f\"Added dose information. Max dose: {max_dose}\")\n",
    "print(f\"Final merged dataset shape: {merged_dataset.shape}\")\n",
    "merged_dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Rank/Dose Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rank/dose pairs from query results\n",
    "def create_rank_dose_pairs(data, value_column='bmdValue', dose_column='max_dose'):\n",
    "    \"\"\"Create rank/dose pairs from data\"\"\"\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    rank_data = data.copy()\n",
    "    \n",
    "    # Create ranks (1 = best/lowest value)\n",
    "    rank_data['rank'] = rank_data[value_column].rank(method='min')\n",
    "    rank_data['percentile_rank'] = rank_data[value_column].rank(pct=True)\n",
    "    \n",
    "    # Create rank/dose pairs\n",
    "    pairs = rank_data[[\n",
    "        'probe_id', 'geneSymbol', 'rank', 'percentile_rank', \n",
    "        value_column, dose_column\n",
    "    ]].copy()\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Create the rank/dose pairs\n",
    "rank_dose_pairs = create_rank_dose_pairs(merged_dataset)\n",
    "\n",
    "print(f\"Created {len(rank_dose_pairs)} rank/dose pairs\")\n",
    "print(\"\\nTop 10 ranked items:\")\n",
    "rank_dose_pairs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Custom query for rank/dose pairs\n",
    "# Create rank/dose pairs directly from database query\n",
    "\n",
    "custom_rank_query = sink.execute_query(\"\"\"\n",
    "    SELECT \n",
    "        p.id as probe_id,\n",
    "        rg.geneSymbol,\n",
    "        RANK() OVER (ORDER BY p.id) as custom_rank,\n",
    "        1000.0 as reference_dose,\n",
    "        p.id * 1.5 as synthetic_value\n",
    "    FROM probes p\n",
    "    LEFT JOIN referenceGeneAnnotations rga ON p.id = rga.probeId\n",
    "    LEFT JOIN referenceGenes rg ON rga.referenceGeneId = rg.id\n",
    "    WHERE rg.geneSymbol IS NOT NULL\n",
    "    ORDER BY custom_rank\n",
    "    LIMIT 20\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Custom rank/dose query: {len(custom_rank_query)} results\")\n",
    "custom_rank_query.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of what we created\n",
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"1. DuckDB datasets created: probe_dataset ({len(probe_dataset)} rows), dose_dataset ({len(dose_dataset)} rows)\")\n",
    "print(f\"2. TypeScript interface parsed: {ts_schema['interface_name']} with {len(ts_schema['properties'])} properties\")\n",
    "print(f\"3. JSON data parsed: {len(json_dataset)} records\")\n",
    "print(f\"4. Merged dataset: {len(merged_dataset)} records\")\n",
    "print(f\"5. Rank/dose pairs: {len(rank_dose_pairs)} pairs\")\n",
    "\n",
    "print(\"\\n=== AVAILABLE VARIABLES ===\")\n",
    "print(\"- probe_dataset: Basic probe data from DuckDB\")\n",
    "print(\"- dose_dataset: Dose information from DuckDB\") \n",
    "print(\"- json_dataset: Parsed JSON data\")\n",
    "print(\"- merged_dataset: Combined data\")\n",
    "print(\"- rank_dose_pairs: Analysis-ready rank/dose pairs\")\n",
    "print(\"- sink: DuckDB connection for custom queries\")\n",
    "\n",
    "print(\"\\n=== NEXT STEPS ===\")\n",
    "print(\"1. Replace sample TypeScript content with your .ts file\")\n",
    "print(\"2. Replace sample JSON with your actual JSON file\")\n",
    "print(\"3. Customize merge logic for your specific needs\")\n",
    "print(\"4. Modify rank/dose pair creation as needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "sink.disconnect()\n",
    "print(\"Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}